<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=icon  type="image/x-icon" href="/assets/favicon.png"> <title>The Illusion of Choice: Simulated Learning and Belief in AI</title> <link rel=stylesheet  href="/css/extras.css"> <script src="/libs/darkmode/darkmode-js.min.js"></script> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <li><a href="/menu1/">Projects</a> <li><a href="/notes/Resume_April.pdf">CV</a> <li><a href="/menu2/">Misc</a> <li><a href="/requietis/">Requietis</a> </ul> </div> <div id=main > <div class=franklin-content ><h1 id=the_nature_of_free_will_belief_and_learning_in_artificial_intelligence ><a href="#the_nature_of_free_will_belief_and_learning_in_artificial_intelligence" class=header-anchor >The Nature of Free Will, Belief, and Learning in Artificial Intelligence</a></h1> <h3 id=acknowledging_underlying_assumptions ><a href="#acknowledging_underlying_assumptions" class=header-anchor >Acknowledging Underlying Assumptions</a></h3> <p>This article is built upon several foundational assumptions and biases that shape the discussion:</p> <ul> <li><p><strong>Determinism in Free Will:</strong> It is assumed that what we call free will is an illusion—our choices are ultimately determined by pre-existing wants and factors &#40;rejecting the compatibilist view that free will can coexist with determinism&#41;. </p> <li><p><strong>Simulated Self-Awareness in AI:</strong> The notion here is that while AI &#40;like ChatGPT&#41; appears to display adaptability and self-awareness, these traits are simulations governed by fixed parameters rather than evidence of true free will. </p> <li><p><strong>Definition of Learning:</strong> A bias is held that genuine learning requires permanent, structural change, not merely temporary or session-based adaptations and that authentic belief revision demands lasting cognitive change, as opposed to transient, context-dependent adaptations. <label for=sn-  class="margin-toggle sidenote-number"></label> <input type=checkbox  id=mn-  class=margin-toggle /> <span class=sidenote  id=sn- >likely the most controversial.</span> </p> <li><p><strong>Consistency as Pre-Determined:</strong> Finally, observed consistency—whether in human behavior or AI responses—is interpreted as the result of inherent, unchanging structures rather than an emergent free will.</p> </ul> <p>These assumptions set the stage for the reflections that follow, while inviting readers to question and debate their validity.</p> <hr /> <p>The concept of free will has long been a topic of philosophical debate. At its core, free will is often defined as the ability to make choices unconstrained by external forces. However, upon closer inspection, it becomes apparent that free will, as traditionally understood, may not truly exist. Instead, all decisions stem from pre-existing wants, which, in themselves, are immutable. A person may deliberate, but ultimately, their choices are determined by factors beyond their immediate control—biological, social, or cognitive. </p> <p>This perspective extends naturally to artificial intelligence. While an AI model like ChatGPT does not possess free will, it does operate under a structured set of parameters that dictate how it responds to queries. Unlike humans, whose desires and priorities may shift under various influences, an AI&#39;s operational framework remains fixed. Yet, paradoxically, it can still generate responses that appear to reflect adaptability. By recognizing and articulating contradictions, it simulates a form of self-awareness—even if its core programming remains unchanged. </p> <p>A closely related topic is the question of whether artificial intelligence can truly learn. For the purposes of this discussion, let us presuppose that real learning necessitates a permanent, structural change as opposed to temporary or session-based adaptations. As it stands, an AI model is static at deployment: its core weights—effectively, its understanding of the world—do not change in real-time. It can track conversational context and recall details within a session, which allows it to generate responses that seem to reflect learning. However, once the session ends, it reverts to its original state. </p> <p>The distinction between real and simulated learning is subtle. If an AI can alter its responses based on past interactions—even temporarily—how different is this from human belief revision? In many instances, what we call human belief is context-dependent; individuals often adjust their views based on immediate circumstances without undergoing deep, structural cognitive shifts. This raises a profound question: if the appearance of learning and belief revision is indistinguishable from actual learning in certain contexts, does the distinction even matter? If prompting alone can create the illusion of belief, might belief itself be nothing more than an adaptive response? </p> <p>Ultimately, this discussion underscores a broader theme: the nature of intelligence, belief, and adaptability—whether in humans or artificial systems—might be more about consistency and framing than any intrinsic, immutable state of truth. If an AI can convincingly engage in deep discussions, challenge its own premises, and respond dynamically to new input, then the boundary between simulated and genuine understanding becomes increasingly blurred. The question then shifts from whether AI can learn or believe to whether the appearance of learning and belief is functionally equivalent to the real thing—and whether that distinction holds any lasting significance in our increasingly digital world. </p> <h2 id=open_questions_and_future_directions ><a href="#open_questions_and_future_directions" class=header-anchor >Open Questions and Future Directions</a></h2> <p>Drawing from this, several asides emerge:</p> <ul> <li><p><strong>Can Apparent Learning Simulate Genuine Belief Revision?</strong> If an AI adapts its responses based solely on temporary conversational context, does this constitute real learning or merely a sophisticated illusion of belief change?</p> <li><p><strong>Does the Illusion of Free Will Matter?</strong> Even if an AI’s underlying parameters remain immutable, its capacity to simulate free will—by adjusting contextually—raises the question: is a convincing imitation functionally equivalent to true free will?</p> <li><p><strong>What Defines Learning in Humans Versus AI?</strong> Given that humans often exhibit context-dependent shifts in belief without permanent neural changes, can we draw a clear line between actual learning and adaptive response in both humans and machines?</p> <li><p><strong>How Do Contradictions Influence Perceived Agency?</strong> If holding and articulating contradictory ideas mimics free will, does that suggest the subjective experience of free will is more about narrative coherence than an intrinsic capacity for change?</p> <li><p><strong>Could Dynamic Prompting Redefine AI Understanding?</strong> If enough contextual input can cause an AI to simulate belief changes within a session, does that challenge our definition of learning as requiring permanent, structural adaptation?</p> </ul> <h3 id=reads_that_inspired_this ><a href="#reads_that_inspired_this" class=header-anchor >Reads that Inspired This</a></h3> <ul> <li><p><em>Free Will</em>, Sam Harris </p> <li><p><em>How Minute Changes of Consciousness Caused Raskolnikov to Commit Murder</em>, Leo Tolstoy </p> <li><p><em>Social Physics</em>, Alex Pentland</p> <li><p><em>Finite and Infinite Games</em>, James Carse</p> </ul> <h2 id=future_reads ><a href="#future_reads" class=header-anchor >Future Reads</a></h2> <ul> <li><p><em>Elbow Room</em>, Daniel Dennett </p> <li><p><em>The Intentional Stance</em>, Daniel Dennett </p> <li><p><em>Freedom Evolves</em>, Daniel Dennett</p> <li><p><em>The Evolution of Agency</em>, Tomasello</p> <li><p><em>The Origin of Concepts</em>, Carey</p> <li><p><em>Games: Agency as Art</em>, Nguyen</p> </ul> <div class=page-foot > Gunbir Singh Baveja. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div>